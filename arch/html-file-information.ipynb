{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archivesunleashed/notebooks/blob/main/arch/html-file-information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTML Information Dataset Exploration\n",
        "\n",
        "We're going to take a look at a few examples of how we can explore the HTML Information dataset. \n",
        "\n",
        "The first thing we need to do is enter the URL for our HTML Information dataset in the cell below. You can get this by right clicking the Download icon, and selecting \"Copy Link\"."
      ],
      "metadata": {
        "id": "vAyuRQ2PJIdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'https://webdata.archive-it.org/ait/files/download/ARCHIVEIT-14462/TextFilesInformationExtraction/html-file-information.csv.gz?access=UCQ7VUUU4NDLKSGIPQD2R2WUGLOQXWPQ' #@param {type:\"string\"}\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "RfhJiesWVpAf",
        "outputId": "507325b4-2e56-4aaf-bc7b-55b38fe221c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://webdata.archive-it.org/ait/files/download/ARCHIVEIT-14462/TextFilesInformationExtraction/html-file-information.csv.gz?access=UCQ7VUUU4NDLKSGIPQD2R2WUGLOQXWPQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas\n",
        "\n",
        "Next, we'll setup our environment so we can load our HTML Information dataset into [pandas](https://pandas.pydata.org) DataFrames. If you're unfamiliar with DataFrames, but you've worked with spreadsheets before, you should quickly feel comfortable."
      ],
      "metadata": {
        "id": "Z14F2cIWJVW0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Chh6tt3HHF1s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Table Display\n",
        "\n",
        "Colab includes an extension that renders pandas DataFrames into interactive displays that can be filtered, sorted, and explored dynamically. This can be very useful for taking a look at what each DataFrame provides, and doing some intital filtering!\n",
        "\n",
        "Data table display for pandas DataFrames can be enabled by running:\n",
        "```python\n",
        "%load_ext google.colab.data_table\n",
        "```\n",
        "and disabled by running\n",
        "```python\n",
        "%unload_ext google.colab.data_table\n",
        "```"
      ],
      "metadata": {
        "id": "sH81XCf3I3xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext google.colab.data_table"
      ],
      "metadata": {
        "id": "-qyCnbvBI7n6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading our ARCH Dataset as a DataFrame\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Next, we'll create pandas DataFrame from our dataset and show a preview of it using the Data Table Display."
      ],
      "metadata": {
        "id": "6prR7j1zI_D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html = pd.read_csv(dataset, compression='gzip')\n",
        "html"
      ],
      "metadata": {
        "id": "YL0LQaUNHRKx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HPwOCNAvqMe"
      },
      "source": [
        "# Data Analysis\n",
        "\n",
        "Now that we have all of our datasets loaded up, we can begin to work with them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Pkg0prv3BE"
      },
      "source": [
        "## Counting total files, and unique files\n",
        "\n",
        "Let's take a quick look at how to count items in DataFrames, and use total and unique files as an example to work with.\n",
        "\n",
        "It's definitely work checking out the [pandas documentation](https://pandas.pydata.org/docs/index.html). There are a lot of good examples available, along with a robust [API reference](https://pandas.pydata.org/docs/reference/index.html#api)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFX4Gl3wv7bi"
      },
      "source": [
        "\n",
        "### How many html files are in this collection?\n",
        "\n",
        "We can take our `html` variable and try a couple of functions to get the same answer.\n",
        "\n",
        "1.   `len(html.index)`\n",
        "  * Get the length of the DataFrame's index.\n",
        "2.   `html.shape[0]`\n",
        "  * Get the shape or dimensionality of the DataFrame, and take the first item in the tuple.\n",
        "3.  `html.count()`\n",
        "  * Count the number of rows for each column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTv8Oet3jiTH"
      },
      "source": [
        "len(html.index)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rYEERnTjifk"
      },
      "source": [
        "html.shape[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn-1v127aKIG"
      },
      "source": [
        "html.count()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38veKiPhwKo4"
      },
      "source": [
        "### How many unique html files are in the collection?\n",
        "\n",
        " We can see if an HTML file is unique or not by computing an [MD5 hash](https://en.wikipedia.org/wiki/MD5#MD5_hashes) of it, and comparing them. The exact same html file might have a filename of `example.html` or `foo.html`. If the hash is computed for each, we can see that even with different file names, they are actually the same html file. So, since we have both a `MD5` and `SHA1` hash column available in our DataFrame, we can just find the unique values, and count them!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WesM3kQowM5B"
      },
      "source": [
        "len(html.md5.unique())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIXkI0-1wWQf"
      },
      "source": [
        "### What are the top 10 most occurring html files in the collection?\n",
        "\n",
        "Here we can take advantage of [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) to provide us with a list of MD5 hashes and their respective counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ts03OFyjPIM"
      },
      "source": [
        "html[\"md5\"].value_counts().head(10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG7pGZUEwlaI"
      },
      "source": [
        "\n",
        "### What's the information around all of the occurances of `d41d8cd98f00b204e9800998ecf8427e`?\n",
        "\n",
        "What, you mean you don't know what `d41d8cd98f00b204e9800998ecf8427e` means? \n",
        "\n",
        "Let's find those HTML files in the DataFrame. We can here see some of the filenames used, its dimensions, and its URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msmmm65lkSIK"
      },
      "source": [
        "html.loc[html[\"md5\"] == \"d41d8cd98f00b204e9800998ecf8427e\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbLLZW2awzCv"
      },
      "source": [
        "### What are the top 10 most occuring filenames in the collection?\n",
        "\n",
        "Note that this is of course different than the MD5 results up above. Here we are focusing _just_ on filename. So `a16180790160.html ` for example, might actually be referring to different HTML files who happen to have the same name.\n",
        "\n",
        "Here we can use `value_counts()` again, but this time we'll create a variable for the top filenames so we can use it later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQaw54ACkwdZ"
      },
      "source": [
        "top_filenames = html[\"filename\"].value_counts().head(10)\n",
        "top_filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7F3re20BQRI"
      },
      "source": [
        "### Let's create our first graph!\n",
        "\n",
        "We'll first plot the data with the pandas [plot](https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html) functionality, and then with [Altair](https://altair-viz.github.io/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRvlstfsBWEZ"
      },
      "source": [
        "top_filenames_chart = top_filenames.plot.bar(figsize=(25, 10))\n",
        "\n",
        "top_filenames_chart.set_title(\"Top Filenames\", fontsize=22)\n",
        "top_filenames_chart.set_xlabel(\"Filename\", fontsize=20)\n",
        "top_filenames_chart.set_ylabel(\"Count\", fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQgeOObvgLvK"
      },
      "source": [
        "Now let's setup [Altair](https://altair-viz.github.io/), and plot the data. Altair is useful for creating vizualizations since they can be easily exported as a PNG or SVG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Z4J6qjWaVM"
      },
      "source": [
        "import altair as alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0xwvILYWkgg"
      },
      "source": [
        "top_filenames_altair = (\n",
        "    html[\"filename\"]\n",
        "    .value_counts()\n",
        "    .head(10)\n",
        "    .rename_axis(\"Filename\")\n",
        "    .reset_index(name=\"Count\")\n",
        ")\n",
        "\n",
        "filenames_bar = (\n",
        "    alt.Chart(top_filenames_altair)\n",
        "    .mark_bar()\n",
        "    .encode(x=alt.X(\"Filename:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
        ")\n",
        "\n",
        "filenames_rule = (\n",
        "    alt.Chart(top_filenames_altair).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
        ")\n",
        "\n",
        "\n",
        "filenames_text = filenames_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
        "    text=\"Count:Q\"\n",
        ")\n",
        "\n",
        "(filenames_bar + filenames_rule + filenames_text).properties(\n",
        "    width=1400, height=700, title=\"Top Filenames\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BneaN9cgGoly"
      },
      "source": [
        "### How about a file format distribution?\n",
        "\n",
        "What _kind_ of html files are present? We can discover this by checking their \"media type\", or [MIME type](https://en.wikipedia.org/wiki/Media_type). \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDd-J8D-GwDk"
      },
      "source": [
        "html_mime_types = (\n",
        "    html[\"mime_type_tika\"]\n",
        "    .value_counts()\n",
        "    .head(5)\n",
        "    .rename_axis(\"MIME Type\")\n",
        "    .reset_index(name=\"Count\")\n",
        ")\n",
        "\n",
        "html_mimes_bar = (\n",
        "    alt.Chart(html_mime_types)\n",
        "    .mark_bar()\n",
        "    .encode(x=alt.X(\"MIME Type:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
        ")\n",
        "\n",
        "html_mime_rule = (\n",
        "    alt.Chart(html_mime_types).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
        ")\n",
        "\n",
        "html_mime_text = html_mimes_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
        "    text=\"Count:Q\"\n",
        ")\n",
        "\n",
        "(html_mimes_bar + html_mime_rule + html_mime_text).properties(\n",
        "    width=1400, height=700, title=\"HTML File Format Distribution\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUJR-jjqNxCL"
      },
      "source": [
        "### How do I get the actual html?\n",
        "\n",
        "...or, how do I get to the actual binary files described by each file format information derivative?\n",
        "\n",
        "There are a few options!\n",
        "\n",
        "1. `wget` or `curl` from the live URL, or a replay URL\n",
        "  * Live web URL\n",
        "    * `wget` or `curl` the value of the `url` column\n",
        "  * Replay web URL\n",
        "    * `wget` or `curl` the value of the `crawl_date` and `url` column using the following pattern:\n",
        "      * `https://web.archive.org/web/` + `crawl_date` + `/` + `url`\n",
        "        * https://web.archive.org/web/20120119124734/http://www.archive.org/images/glogo.png\n",
        "      * `http://wayback.archive-it.org/14462/` + `crawl_date` + `/` + `url`\n",
        "        * https://wayback.archive-it.org/14462/20210524212740/https://ruebot.net/visualization/elxn42/featured_hu33a17dfb90e2c5ed77f783db14a6e53a_5126291_550x0_resize_q90_box_2.png\n",
        "2. Use a scripting language, such as Python\n",
        "  * Make use of the `url` and `filename` columns (and `crawl_date` if you want to use the replay URL)\n",
        "  * `import requests`\n",
        "  * `requests.get(url, allow_redirects=True)`\n",
        "  * `open('filename', 'wb').write(r.content)`\n",
        "3. Use the [Archives Unleashed Toolkit](https://aut.docs.archivesunleashed.org/docs/extract-binary) (if you have access to the W/ARC files)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wanted to download the HTML files using the replay URL, below is a method for doing so.\n",
        "\n",
        "First, you'll want to setup a replay url base url. Here we'll use the Archive-It Wayback instance for the collection."
      ],
      "metadata": {
        "id": "8yoFE2xLAlwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wayback_url = 'http://wayback.archive-it.org/14462/'"
      ],
      "metadata": {
        "id": "RxrOHn_2AicZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll create a new column using a lambda function. If you're familiar working with spreadsheets, what we're doing here is basically concatenating some column values together and creating a new column."
      ],
      "metadata": {
        "id": "jCTmrEBGA-Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html['replay_url'] = html.apply(lambda row: str(wayback_url + str(row['crawl_date']) + \"/\" + row['url']), axis=1)"
      ],
      "metadata": {
        "id": "p5HoWxkFA6C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can export that new column we created out to a file, so we can use it with `wget` to download all the html files!"
      ],
      "metadata": {
        "id": "q87tSYyIBIiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html['replay_url'].head().to_csv('14462_html_urls.txt', index=False, header=False)"
      ],
      "metadata": {
        "id": "wyhpsf9wBN1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can pass the file to `wget` to use as a download list. You can also speed this process up using `xargs` or `parallel`."
      ],
      "metadata": {
        "id": "81a3q7feu5Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --random-wait -i 14462_html_urls.txt"
      ],
      "metadata": {
        "id": "D_p4qGKoBRaZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}